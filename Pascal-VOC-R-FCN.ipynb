{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pascal VOC R-FCN.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "AMlXJ2yIV8e7",
        "sv3Zm042QGJy",
        "A_tyvKnBP6qD",
        "sOcbTFEiPBKA",
        "xMckMSJqFMyc",
        "HnjQgJZiGAcA",
        "8vAGvftxHu8K",
        "sejKIYoJ3wTh",
        "RPN8liiQc7Ue"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65t7YUhnzDCE"
      },
      "source": [
        "## Pascal VOC Dataset Tensorflow Object Detection API Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMlXJ2yIV8e7"
      },
      "source": [
        "## Choosing a Pretrained Model\n",
        "The model that will be trained in this Colab notebook is `rfcn_resnet101`.\n",
        "Link to [all pretrained models](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf1_detection_zoo.md)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3_Ns54i3HgO"
      },
      "source": [
        "\n",
        "\n",
        "# Models to be trained in this project\n",
        "MODELS_CONFIG = {\n",
        "    'faster_rcnn_resnet101': {\n",
        "        'model_name': 'faster_rcnn_resnet101_coco_2018_01_28',\n",
        "        'pipeline_file': 'faster_rcnn_resnet101_voc07.config',\n",
        "    },\n",
        "    'rfcn_resnet101': {\n",
        "        'model_name': 'rfcn_resnet101_coco_2018_01_28',\n",
        "        'pipeline_file': 'rfcn_resnet101_coco.config',\n",
        "    },\n",
        "    'ssd_inception_v2': {\n",
        "        'model_name': 'ssd_inception_v2_coco_2018_01_28',\n",
        "        'pipeline_file': 'ssd_inception_v2_coco.config',\n",
        "    }\n",
        "}\n",
        "\n",
        "# We will train R-FCN in this Colab notebook\n",
        "selected_model = 'rfcn_resnet101'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sv3Zm042QGJy"
      },
      "source": [
        "## Installing Required Packages and Importing Required Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCgkd3v91odY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16147a21-449e-48a4-c61b-3d466cafeccb"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68StUELaQPS2"
      },
      "source": [
        "!apt-get install -qq protobuf-compiler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2FTqPmf8QnE"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "import urllib.request\n",
        "import tarfile\n",
        "\n",
        "from google.colab import files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_tyvKnBP6qD"
      },
      "source": [
        "## Downloading TensorFlow Model Garden and Preparing TensorFlow Object Detection API\n",
        "1. Clones [TensorFlow Model Garden](https://github.com/tensorflow/models.git) from the offical git repo. The repo contains the object detection API we are interested in. \n",
        "2. Tests the model builder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIxz1GqJQA3f"
      },
      "source": [
        "# Downloads TensorFlow Model Garden\n",
        "!git clone --q https://github.com/tensorflow/models.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iHEpitVz739"
      },
      "source": [
        "# Installs the Object Detection API\n",
        "%%bash\n",
        "cd models/research\n",
        "# Compiles protos.\n",
        "protoc object_detection/protos/*.proto --python_out=.\n",
        "# Installs TensorFlow Object Detection API.\n",
        "cp object_detection/packages/tf1/setup.py .\n",
        "python -m pip install ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bMNsrwTSJi2"
      },
      "source": [
        "# Tests the model builder\n",
        "!python /content/models/research/object_detection/builders/model_builder_tf1_test.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOcbTFEiPBKA"
      },
      "source": [
        "## Downloading the Dataset and Generating TFRecords\n",
        "1. Downloads the dataset from the [source](http://host.robots.ox.ac.uk/pascal/VOC/)  and extracts them.\n",
        "2. Generates TFRecords for training and validation image files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mt-a1NcWk5z7"
      },
      "source": [
        "# Downloads the dataset\n",
        "\n",
        "# Source: http://host.robots.ox.ac.uk/pascal/VOC/\n",
        "# Source2: https://data.deepai.org/PASCALVOC2007.zip\n",
        "\n",
        "# Changes directory\n",
        "os.chdir(\"/content\")\n",
        "\n",
        "# Downloads the dataset tar file\n",
        "!wget http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtrainval_06-Nov-2007.tar\n",
        "\n",
        "# Extracts the dataset\n",
        "tar = tarfile.open('VOCtrainval_06-Nov-2007.tar')\n",
        "tar.extractall()\n",
        "tar.close()\n",
        "\n",
        "# Deletes unneeded tar file\n",
        "!rm -rf VOCtrainval_06-Nov-2007.tar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dx4_C6kEiz_A"
      },
      "source": [
        "# Generates TFRecord for the training and validation image files\n",
        "\n",
        "# Changes directory\n",
        "os.chdir(\"/content\")\n",
        "\n",
        "# Generates TFRecord for the training image files\n",
        "!python models/research/object_detection/dataset_tools/create_pascal_tf_record.py \\\n",
        "    --label_map_path=/content/models/research/object_detection/data/pascal_label_map.pbtxt \\\n",
        "    --data_dir=/content/VOCdevkit \\\n",
        "    --year=VOC2007 \\\n",
        "    --set=train \\\n",
        "    --output_path=/content/pascal_train.record \n",
        "\n",
        "# Generates TFRecord for the validation image files\n",
        "!python models/research/object_detection/dataset_tools/create_pascal_tf_record.py \\\n",
        "    --label_map_path=/content/models/research/object_detection/data/pascal_label_map.pbtxt \\\n",
        "    --data_dir=/content/VOCdevkit \\\n",
        "    --year=VOC2007 \\\n",
        "    --set=val \\\n",
        "    --output_path=/content/pascal_val.record"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMckMSJqFMyc"
      },
      "source": [
        "## Downloading Pretrained Model\n",
        "Based on the model selected at the top of this notebook, downloads the model and extracts its content."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvN9Cw65FQzB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eed6e8bb-319d-4c3e-83b6-73fdf068d5a9"
      },
      "source": [
        "%cd /content/models/research\n",
        "\n",
        "# The name of the object detection model to be used\n",
        "MODEL = MODELS_CONFIG[selected_model]['model_name']\n",
        "\n",
        "# The name of the selected pipeline file\n",
        "pipeline_file = MODELS_CONFIG[selected_model]['pipeline_file']\n",
        "\n",
        "# The name of the tar file that contains the model\n",
        "MODEL_FILE = MODEL + '.tar.gz'\n",
        "\n",
        "# Base link that contains pretrained models\n",
        "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
        "\n",
        "# The name of the destination folder where the model will be saved\n",
        "fine_tune_dir = '/content/models/research/pretrained_model'\n",
        "\n",
        "# Downloads the selected model\n",
        "if not (os.path.exists(MODEL_FILE)):\n",
        "    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
        "\n",
        "# Extracts the content of the tar file\n",
        "tar = tarfile.open(MODEL_FILE)\n",
        "tar.extractall()\n",
        "tar.close()\n",
        "\n",
        "# Changes the name of the folder that contains the downloaded model\n",
        "os.remove(MODEL_FILE)\n",
        "if (os.path.exists(fine_tune_dir)):\n",
        "    shutil.rmtree(fine_tune_dir)\n",
        "os.rename(MODEL, fine_tune_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbjXKVMmFk47"
      },
      "source": [
        "# Checks the content of the folder that contains the pretrained model\n",
        "!echo {fine_tune_dir}\n",
        "!ls -alh {fine_tune_dir}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnjQgJZiGAcA"
      },
      "source": [
        "## Configuring Training Pipeline\n",
        "1. Sets the paths for the TFRecord files and label map file, and sets the batch_size, num_steps, num_classes, num_examples, num_visualizations and max_evals parameters in the configuration file.\n",
        "2. Configures model_main.py file to save and evaluate the model at every 2500 steps.\n",
        "3. Creates a folder to save the model at each checkpoint while training. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuXXZLVEG8sO"
      },
      "source": [
        "# The folder where the model will be saved at each checkpoint while training\n",
        "model_dir = 'training/'\n",
        "\n",
        "# Removes the content in the folder to fresh start\n",
        "!rm -rf {model_dir}\n",
        "os.makedirs(model_dir, exist_ok=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "az14XVo31Ujp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28f98ca6-1c47-4b01-9d03-07ff1ccbe3bb"
      },
      "source": [
        "\n",
        "# The path to the folder containing all the sample config files\n",
        "CONFIG_BASE = \"/content/models/research/object_detection/samples/configs/\"\n",
        "\n",
        "# Path to the specified model's config file\n",
        "model_pipeline = os.path.join(CONFIG_BASE, pipeline_file)\n",
        "print(model_pipeline)\n",
        "\n",
        "# Path to the model_main.py file\n",
        "model_main_config = \"/content/models/research/object_detection/model_main.py\"\n",
        "print(model_main_config)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research/object_detection/samples/configs/rfcn_resnet101_coco.config\n",
            "/content/models/research/object_detection/model_main.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YBkAYAbEZbY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "001c79ce-fdbc-40a9-b268-a86508a3614b"
      },
      "source": [
        "%%writefile {model_pipeline}\n",
        "# R-FCN with Resnet-101 (v1),  configuration for MSCOCO Dataset.\n",
        "# Users should configure the fine_tune_checkpoint field in the train config as\n",
        "# well as the label_map_path and input_path fields in the train_input_reader and\n",
        "# eval_input_reader. Search for \"PATH_TO_BE_CONFIGURED\" to find the fields that\n",
        "# should be configured.\n",
        "\n",
        "model {\n",
        "  faster_rcnn {\n",
        "    num_classes: 20\n",
        "    image_resizer {\n",
        "      keep_aspect_ratio_resizer {\n",
        "        min_dimension: 600\n",
        "        max_dimension: 1024\n",
        "      }\n",
        "    }\n",
        "    feature_extractor {\n",
        "      type: 'faster_rcnn_resnet101'\n",
        "      first_stage_features_stride: 16\n",
        "    }\n",
        "    first_stage_anchor_generator {\n",
        "      grid_anchor_generator {\n",
        "        scales: [0.25, 0.5, 1.0, 2.0]\n",
        "        aspect_ratios: [0.5, 1.0, 2.0]\n",
        "        height_stride: 16\n",
        "        width_stride: 16\n",
        "      }\n",
        "    }\n",
        "    first_stage_box_predictor_conv_hyperparams {\n",
        "      op: CONV\n",
        "      regularizer {\n",
        "        l2_regularizer {\n",
        "          weight: 0.0\n",
        "        }\n",
        "      }\n",
        "      initializer {\n",
        "        truncated_normal_initializer {\n",
        "          stddev: 0.01\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "    first_stage_nms_score_threshold: 0.0\n",
        "    first_stage_nms_iou_threshold: 0.7\n",
        "    first_stage_max_proposals: 300\n",
        "    first_stage_localization_loss_weight: 2.0\n",
        "    first_stage_objectness_loss_weight: 1.0\n",
        "    second_stage_box_predictor {\n",
        "      rfcn_box_predictor {\n",
        "        conv_hyperparams {\n",
        "          op: CONV\n",
        "          regularizer {\n",
        "            l2_regularizer {\n",
        "              weight: 0.0\n",
        "            }\n",
        "          }\n",
        "          initializer {\n",
        "            truncated_normal_initializer {\n",
        "              stddev: 0.01\n",
        "            }\n",
        "          }\n",
        "        }\n",
        "        crop_height: 18\n",
        "        crop_width: 18\n",
        "        num_spatial_bins_height: 3\n",
        "        num_spatial_bins_width: 3\n",
        "      }\n",
        "    }\n",
        "    second_stage_post_processing {\n",
        "      batch_non_max_suppression {\n",
        "        score_threshold: 0.0\n",
        "        iou_threshold: 0.6\n",
        "        max_detections_per_class: 100\n",
        "        max_total_detections: 300\n",
        "      }\n",
        "      score_converter: SOFTMAX\n",
        "    }\n",
        "    second_stage_localization_loss_weight: 2.0\n",
        "    second_stage_classification_loss_weight: 1.0\n",
        "  }\n",
        "}\n",
        "\n",
        "train_config: {\n",
        "  batch_size: 1\n",
        "  optimizer {\n",
        "    momentum_optimizer: {\n",
        "      learning_rate: {\n",
        "        manual_step_learning_rate {\n",
        "          initial_learning_rate: 0.0003\n",
        "          schedule {\n",
        "            step: 900000\n",
        "            learning_rate: .00003\n",
        "          }\n",
        "          schedule {\n",
        "            step: 1200000\n",
        "            learning_rate: .000003\n",
        "          }\n",
        "        }\n",
        "      }\n",
        "      momentum_optimizer_value: 0.9\n",
        "    }\n",
        "    use_moving_average: false\n",
        "  }\n",
        "  gradient_clipping_by_norm: 10.0\n",
        "  fine_tune_checkpoint: \"/content/models/research/pretrained_model/model.ckpt\"\n",
        "  from_detection_checkpoint: true\n",
        "  # The number of steps the model will be trained on, we will change this parameter when using model_main.py\n",
        "  num_steps: 100\n",
        "  data_augmentation_options {\n",
        "    random_horizontal_flip {\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "train_input_reader: {\n",
        "  tf_record_input_reader {\n",
        "    input_path: \"/content/pascal_train.record\"\n",
        "  }\n",
        "  label_map_path: \"/content/models/research/object_detection/data/pascal_label_map.pbtxt\"\n",
        "}\n",
        "\n",
        "eval_config: {\n",
        "  # The number of images in validation set\n",
        "  num_examples: 2510\n",
        "  # The number of images to display in TensorBoard while testing model's performance\n",
        "  num_visualizations: 20\n",
        "  # The number of evalutions executed at the training phase, we will remove this parameter to evaluate indefinitely\n",
        "  #max_evals: 1\n",
        "}\n",
        "\n",
        "eval_input_reader: {\n",
        "  tf_record_input_reader {\n",
        "    input_path: \"/content/pascal_val.record\"\n",
        "  }\n",
        "  label_map_path: \"/content/models/research/object_detection/data/pascal_label_map.pbtxt\"\n",
        "  shuffle: false\n",
        "  num_readers: 1\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting /content/models/research/object_detection/samples/configs/rfcn_resnet101_coco.config\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGOZlT_dhj2y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62e5039f-ebd0-481a-bfb5-17c34e5f1a2b"
      },
      "source": [
        "%%writefile {model_main_config}\n",
        "# Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\"\"\"Binary to run train and evaluation on object detection model.\"\"\"\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "from absl import flags\n",
        "\n",
        "import tensorflow.compat.v1 as tf\n",
        "\n",
        "from object_detection import model_lib\n",
        "\n",
        "flags.DEFINE_string(\n",
        "    'model_dir', None, 'Path to output model directory '\n",
        "    'where event and checkpoint files will be written.')\n",
        "flags.DEFINE_string('pipeline_config_path', None, 'Path to pipeline config '\n",
        "                    'file.')\n",
        "flags.DEFINE_integer('num_train_steps', None, 'Number of train steps.')\n",
        "flags.DEFINE_boolean('eval_training_data', False,\n",
        "                     'If training data should be evaluated for this job. Note '\n",
        "                     'that one call only use this in eval-only mode, and '\n",
        "                     '`checkpoint_dir` must be supplied.')\n",
        "flags.DEFINE_integer('sample_1_of_n_eval_examples', 1, 'Will sample one of '\n",
        "                     'every n eval input examples, where n is provided.')\n",
        "flags.DEFINE_integer('sample_1_of_n_eval_on_train_examples', 5, 'Will sample '\n",
        "                     'one of every n train input examples for evaluation, '\n",
        "                     'where n is provided. This is only used if '\n",
        "                     '`eval_training_data` is True.')\n",
        "flags.DEFINE_string(\n",
        "    'checkpoint_dir', None, 'Path to directory holding a checkpoint.  If '\n",
        "    '`checkpoint_dir` is provided, this binary operates in eval-only mode, '\n",
        "    'writing resulting metrics to `model_dir`.')\n",
        "flags.DEFINE_boolean(\n",
        "    'run_once', False, 'If running in eval-only mode, whether to run just '\n",
        "    'one round of eval vs running continuously (default).'\n",
        ")\n",
        "flags.DEFINE_integer(\n",
        "    'max_eval_retries', 0, 'If running continuous eval, the maximum number of '\n",
        "    'retries upon encountering tf.errors.InvalidArgumentError. If negative, '\n",
        "    'will always retry the evaluation.'\n",
        ")\n",
        "FLAGS = flags.FLAGS\n",
        "\n",
        "\n",
        "def main(unused_argv):\n",
        "  flags.mark_flag_as_required('model_dir')\n",
        "  flags.mark_flag_as_required('pipeline_config_path')\n",
        "  # Changes the RunConfig to save the model at every 2500 steps.\n",
        "  config = tf.estimator.RunConfig(model_dir=FLAGS.model_dir, save_checkpoints_steps=2500)\n",
        "\n",
        "  train_and_eval_dict = model_lib.create_estimator_and_inputs(\n",
        "      run_config=config,\n",
        "      pipeline_config_path=FLAGS.pipeline_config_path,\n",
        "      train_steps=FLAGS.num_train_steps,\n",
        "      sample_1_of_n_eval_examples=FLAGS.sample_1_of_n_eval_examples,\n",
        "      sample_1_of_n_eval_on_train_examples=(\n",
        "          FLAGS.sample_1_of_n_eval_on_train_examples))\n",
        "  estimator = train_and_eval_dict['estimator']\n",
        "  train_input_fn = train_and_eval_dict['train_input_fn']\n",
        "  eval_input_fns = train_and_eval_dict['eval_input_fns']\n",
        "  eval_on_train_input_fn = train_and_eval_dict['eval_on_train_input_fn']\n",
        "  predict_input_fn = train_and_eval_dict['predict_input_fn']\n",
        "  train_steps = train_and_eval_dict['train_steps']\n",
        "\n",
        "  if FLAGS.checkpoint_dir:\n",
        "    if FLAGS.eval_training_data:\n",
        "      name = 'training_data'\n",
        "      input_fn = eval_on_train_input_fn\n",
        "    else:\n",
        "      name = 'validation_data'\n",
        "      # The first eval input will be evaluated.\n",
        "      input_fn = eval_input_fns[0]\n",
        "    if FLAGS.run_once:\n",
        "      estimator.evaluate(input_fn,\n",
        "                         steps=None,\n",
        "                         checkpoint_path=tf.train.latest_checkpoint(\n",
        "                             FLAGS.checkpoint_dir))\n",
        "    else:\n",
        "      model_lib.continuous_eval(estimator, FLAGS.checkpoint_dir, input_fn,\n",
        "                                train_steps, name, FLAGS.max_eval_retries)\n",
        "  else:\n",
        "    train_spec, eval_specs = model_lib.create_train_and_eval_specs(\n",
        "        train_input_fn,\n",
        "        eval_input_fns,\n",
        "        eval_on_train_input_fn,\n",
        "        predict_input_fn,\n",
        "        train_steps,\n",
        "        eval_on_train_data=False)\n",
        "\n",
        "    # Currently only a single Eval Spec is allowed.\n",
        "    tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  tf.app.run()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting /content/models/research/object_detection/model_main.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vAGvftxHu8K"
      },
      "source": [
        "## Using TensorBoard\n",
        "1. Loads the TensorBoard notebook extension.\n",
        "2. Starts TensorBoard for visualizing training and validation scores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qeKpug-rAw1"
      },
      "source": [
        "# Loads the TensorBoard notebook extension\n",
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgbyUWytoGCP"
      },
      "source": [
        "# Runs TensorBoard to visualize training scores\n",
        "%tensorboard --logdir \"/content/models/research/training\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sejKIYoJ3wTh"
      },
      "source": [
        "## Training\n",
        "Training the model. Read comments at the top of the cells carefully before running cells."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p86I5PeQw4NM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b32d7489-7f32-41d0-e292-5102d8009678"
      },
      "source": [
        "# Mounts Drive to save the model checkpoint to Drive.\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVL_WyMx320d"
      },
      "source": [
        "# I had some problems using model_main.py directly. For this reason, first we will\n",
        "# create a checkpoint, then we will use model_main.py.\n",
        "\n",
        "!python /content/models/research/object_detection/legacy/train.py \\\n",
        "    --logtostderr \\\n",
        "    --train_dir={model_dir} \\\n",
        "    --pipeline_config_path={model_pipeline} \\"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ubG_WtX9l8r"
      },
      "source": [
        "# Loads the model checkpoint from Drive to continue from where\n",
        "# we left in the last session.\n",
        "\n",
        "!rm -rf \"/content/models/research/training/\"*\n",
        "!cp -r \"/content/drive/My Drive/Colab Notebooks/training_rfcn/\"* \"/content/models/research/training/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kuf1HLaIjhK"
      },
      "source": [
        "# Begins training.\n",
        "\n",
        "!python /content/models/research/object_detection/model_main.py \\\n",
        "    --pipeline_config_path={model_pipeline}\\\n",
        "    --num_train_steps=50000 \\\n",
        "    --model_dir={model_dir}\\\n",
        "    --sample_1_of_n_eval_examples=10 \\\n",
        "    --alsologtostderr \\"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUyxnCM3swN5"
      },
      "source": [
        "# Creates a directory to save the model checkpoint to Drive and deletes old files\n",
        "\n",
        "!rm -rf \"/content/drive/My Drive/Colab Notebooks/training_rfcn/\"\n",
        "os.makedirs(\"/content/drive/My Drive/Colab Notebooks/training_rfcn/\", exist_ok=True)\n",
        "\n",
        "# Saves the model checkpoint to Drive\n",
        "\n",
        "!cp -r \"/content/models/research/training/\"* \"/content/drive/My Drive/Colab Notebooks/training_rfcn/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPN8liiQc7Ue"
      },
      "source": [
        "## Exporting the Trained Model\n",
        "After all training sessions are completed, we will export the trained model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upwUdom0lTub"
      },
      "source": [
        "import numpy as np\n",
        "import re\n",
        "\n",
        "# The location where the exported model will be saved in\n",
        "output_directory = '/content/models/research/fine_tuned_model'\n",
        "\n",
        "# Goes through the folder where the model checkpoints are saved and picks the last model checkpoint.\n",
        "lst = os.listdir(model_dir)\n",
        "lst = [l for l in lst if 'model.ckpt-' in l and '.meta' in l]\n",
        "steps=np.array([int(re.findall('\\d+', l)[0]) for l in lst])\n",
        "last_model = lst[steps.argmax()].replace('.meta', '')\n",
        "last_model_path = os.path.join(model_dir, last_model)\n",
        "print(last_model_path)\n",
        "\n",
        "# Exports the inference graph of the model\n",
        "!python /content/models/research/object_detection/export_inference_graph.py \\\n",
        "    --input_type=image_tensor \\\n",
        "    --pipeline_config_path={model_pipeline} \\\n",
        "    --output_directory={output_directory} \\\n",
        "    --trained_checkpoint_prefix={last_model_path}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poERJNYka9ht",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ed44bab2-0f58-400f-b3e8-a593ba630527"
      },
      "source": [
        "# Creates a directory to save the trained model to Drive and deletes old files\n",
        "\n",
        "!rm -rf \"/content/drive/My Drive/Colab Notebooks/model_rfcn/\"\n",
        "os.makedirs(\"/content/drive/My Drive/Colab Notebooks/model_rfcn/\", exist_ok=True)\n",
        "\n",
        "# Saves the trained model to Drive\n",
        "\n",
        "trained_model = os.path.join(output_directory, \"frozen_inference_graph.pb\")\n",
        "label_map_file = \"/content/models/research/object_detection/data/pascal_label_map.pbtxt\"\n",
        "shutil.copy(trained_model, \"/content/drive/My Drive/Colab Notebooks/model_rfcn/\")\n",
        "shutil.copy(label_map_file, \"/content/drive/My Drive/Colab Notebooks/model_rfcn/\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/My Drive/Colab Notebooks/model_rfcn/pascal_label_map.pbtxt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    }
  ]
}